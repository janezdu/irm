{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = 300, 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = torchvision.transforms.Resize((H,W))\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((H,W)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train = torchvision.datasets.ImageFolder(\"data\", transform)\n",
    "# train = torchvision.datasets.ImageFolder(\"data\", transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=None,\n",
    "    pin_memory=False,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get waterbirds; returns dict birds\n",
    "# 1,001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg,1,2,1,/o/ocean/00002178.jpg\n",
    "# img_id,img_filename,y,split,place,place_filename\n",
    "def get_place():\n",
    "    '''\n",
    "    returns:    birds, dict with keys \n",
    "                    '0' for land\n",
    "                    '1' for water\n",
    "    '''\n",
    "    birds = {}\n",
    "    with open('./waterbirds/metadata.csv') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            fname = row['img_filename'].split('/')[-1]\n",
    "            birds[fname] = int(row['place'])\n",
    "    return birds\n",
    "\t\t\t\n",
    "# print(get_place())\n",
    "# '001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg': 1, \n",
    "# '001.Black_footed_Albatross/Black_Footed_Albatross_0009_34.jpg': 1,\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds = get_place()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "      # print(\"batch\", batch_idx)\n",
    "      # for i, (images, labels) in enumerate(test_loader, 0):\n",
    "      # outputs = model(images)\n",
    "      # _, predicted = torch.max(outputs.data, 1)\n",
    "      fname, _ = train_loader.dataset.samples[batch_idx]\n",
    "      # print(sample_fname)\n",
    "      fname = fname.split('/')[-1]\n",
    "      # print(fname)\n",
    "      # TODO: handle batch size > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConvNet(nn.Module):\n",
    "    \"\"\"This is a small neural network.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(BasicConvNet, self).__init__()\n",
    "        self.conv2d1 = nn.Conv2d(3, 2, 3, 1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2d2 = nn.Conv2d(2, 4, 3, 1, 1)\n",
    "        self.maxpool2 = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(12544, num_classes)\n",
    "        self._weight_init()\n",
    "\n",
    "    def _weight_init(self):\n",
    "        for layer in self.children():\n",
    "            if (layer.__class__.__name__ == 'Linear' \\\n",
    "                or layer.__class__.__name__ == 'Conv2d'):\n",
    "                nn.init.kaiming_uniform_(layer.weight.data,0.2)\n",
    "                nn.init.constant_(layer.bias.data,0)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2d2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        # x = x.view(-1,1)\n",
    "        # x = x.view(-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train featurizers and classifiers together for all environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 13.18it/s]\n",
      "  1%|          | 1/100 [00:02<03:46,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 0; Land Loss: 8.986028671264648; Water Loss: 0.6300394535064697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 17.13it/s]\n",
      "  2%|▏         | 2/100 [00:04<03:13,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 1; Land Loss: 0.6716659069061279; Water Loss: 0.6419945359230042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]\n",
      "  2%|▏         | 2/100 [00:04<03:22,  2.07s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_154207/2828554008.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mland_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mland_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mland_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mland_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mland_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "n_epochs = 100\n",
    "birds = get_place()\n",
    "\n",
    "land_net = BasicConvNet(num_classes=2)\n",
    "water_net = BasicConvNet(num_classes=2)\n",
    "land_optimizer = optim.Adam(land_net.parameters(), lr=lr)\n",
    "water_optimizer = optim.Adam(water_net.parameters(), lr=lr)\n",
    "water_optimizer.zero_grad()\n",
    "land_optimizer.zero_grad()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    for batch_idx, data in tqdm(\n",
    "        enumerate(train_loader), total=len(train_loader)\n",
    "    ):\n",
    "        inputs, labels = data\n",
    "\n",
    "        sample_fname, _ = train_loader.dataset.samples[batch_idx]\n",
    "        fname = sample_fname.split('/')[-1]\n",
    "\n",
    "        if birds[fname] == 0:\n",
    "            # Train land-env birds\n",
    "            land_optimizer.zero_grad()\n",
    "            outputs = land_net(inputs)\n",
    "            land_loss = criterion(outputs, labels.type(torch.LongTensor)) \n",
    "            land_loss.backward()\n",
    "            land_optimizer.step()\n",
    "            \n",
    "        elif birds[fname] == 1:\n",
    "            # Train water-env birds\n",
    "            water_optimizer.zero_grad()\n",
    "            outputs = water_net(inputs)\n",
    "            water_loss = criterion(outputs, labels.type(torch.LongTensor)) \n",
    "            water_loss.backward()\n",
    "            water_optimizer.step()\n",
    "\n",
    "\n",
    "    print(f\"E: {epoch}; Land Loss: {land_loss.item()}; Water Loss: {water_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifiers for environments only, freezing featurizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in land_net.children():\n",
    "    if layer.__class__.__name__ == 'Linear':\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "for param in water_net.parameters():\n",
    "    if layer.__class__.__name__ == 'Linear':\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "l_optim_frozen = optim.SGD(filter(lambda p: p.requires_grad, land_net.parameters()), lr=lr)\n",
    "w_optim_frozen = optim.SGD(filter(lambda p: p.requires_grad, water_net.parameters()), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
