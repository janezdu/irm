{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = 300, 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = torchvision.transforms.Resize((H,W))\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((H,W)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train = torchvision.datasets.ImageFolder(\"data\", transform)\n",
    "# train = torchvision.datasets.ImageFolder(\"data\", transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=None,\n",
    "    pin_memory=False,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get waterbirds; returns dict birds\n",
    "# 1,001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg,1,2,1,/o/ocean/00002178.jpg\n",
    "# img_id,img_filename,y,split,place,place_filename\n",
    "def get_place():\n",
    "    '''\n",
    "    returns:    birds, dict with keys \n",
    "                    '0' for land\n",
    "                    '1' for water\n",
    "    '''\n",
    "    birds = {}\n",
    "    with open('./waterbirds/metadata.csv') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            fname = row['img_filename'].split('/')[-1]\n",
    "            birds[fname] = int(row['place'])\n",
    "    return birds\n",
    "\t\t\t\n",
    "# print(get_place())\n",
    "# '001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg': 1, \n",
    "# '001.Black_footed_Albatross/Black_Footed_Albatross_0009_34.jpg': 1,\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds = get_place()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "      # print(\"batch\", batch_idx)\n",
    "      # for i, (images, labels) in enumerate(test_loader, 0):\n",
    "      # outputs = model(images)\n",
    "      # _, predicted = torch.max(outputs.data, 1)\n",
    "      fname, _ = train_loader.dataset.samples[batch_idx]\n",
    "      # print(sample_fname)\n",
    "      fname = fname.split('/')[-1]\n",
    "      # print(fname)\n",
    "      # TODO: handle batch size > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConvNet(nn.Module):\n",
    "    \"\"\"This is a small neural network.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(BasicConvNet, self).__init__()\n",
    "        self.conv2d1 = nn.Conv2d(3, 2, 3, 1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2d2 = nn.Conv2d(2, 4, 3, 1, 1)\n",
    "        self.maxpool2 = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(12544, num_classes)\n",
    "        self._weight_init()\n",
    "\n",
    "    def _weight_init(self):\n",
    "        for layer in self.children():\n",
    "            if (layer.__class__.__name__ == 'Linear' \\\n",
    "                or layer.__class__.__name__ == 'Conv2d'):\n",
    "                nn.init.kaiming_uniform_(layer.weight.data,0.2)\n",
    "                nn.init.constant_(layer.bias.data,0)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2d2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        # x = x.view(-1,1)\n",
    "        # x = x.view(-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train featurizers and classifiers together for all environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 16.62it/s]\n",
      " 10%|█         | 1/10 [00:01<00:16,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 0; Land Loss: 8.124662399291992; Water Loss: 0.07288221269845963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 17.37it/s]\n",
      " 20%|██        | 2/10 [00:03<00:14,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 1; Land Loss: 0.6634581089019775; Water Loss: 0.6668913960456848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 17.34it/s]\n",
      " 30%|███       | 3/10 [00:05<00:12,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 2; Land Loss: 0.689561665058136; Water Loss: 0.6551748514175415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 18.51it/s]\n",
      " 40%|████      | 4/10 [00:06<00:10,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 3; Land Loss: 0.7043549418449402; Water Loss: 0.6436312198638916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 18.83it/s]\n",
      " 50%|█████     | 5/10 [00:08<00:08,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 4; Land Loss: 0.7180204391479492; Water Loss: 0.6340154409408569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 19.30it/s]\n",
      " 60%|██████    | 6/10 [00:10<00:06,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 5; Land Loss: 0.7258651256561279; Water Loss: 0.6262399554252625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 18.69it/s]\n",
      " 70%|███████   | 7/10 [00:11<00:04,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 6; Land Loss: 0.7230496406555176; Water Loss: 0.6199921369552612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 14.80it/s]\n",
      " 80%|████████  | 8/10 [00:13<00:03,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 7; Land Loss: 0.6764634251594543; Water Loss: 0.6149795651435852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 18.09it/s]\n",
      " 90%|█████████ | 9/10 [00:15<00:01,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 8; Land Loss: 0.45330893993377686; Water Loss: 0.6109597086906433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 20.28it/s]\n",
      "100%|██████████| 10/10 [00:16<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 9; Land Loss: 0.35834068059921265; Water Loss: 0.6077364087104797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "n_epochs = 10\n",
    "birds = get_place()\n",
    "\n",
    "land_net = BasicConvNet(num_classes=2)\n",
    "water_net = BasicConvNet(num_classes=2)\n",
    "land_optimizer = optim.Adam(land_net.parameters(), lr=lr)\n",
    "water_optimizer = optim.Adam(water_net.parameters(), lr=lr)\n",
    "water_optimizer.zero_grad()\n",
    "land_optimizer.zero_grad()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    for batch_idx, data in tqdm(\n",
    "        enumerate(train_loader), total=len(train_loader)\n",
    "    ):\n",
    "        inputs, labels = data\n",
    "\n",
    "        sample_fname, _ = train_loader.dataset.samples[batch_idx]\n",
    "        fname = sample_fname.split('/')[-1]\n",
    "\n",
    "        if birds[fname] == 0:\n",
    "            # Train land-env birds\n",
    "            land_optimizer.zero_grad()\n",
    "            outputs = land_net(inputs)\n",
    "            land_loss = criterion(outputs, labels.type(torch.LongTensor)) \n",
    "            land_loss.backward()\n",
    "            land_optimizer.step()\n",
    "            \n",
    "        elif birds[fname] == 1:\n",
    "            # Train water-env birds\n",
    "            water_optimizer.zero_grad()\n",
    "            outputs = water_net(inputs)\n",
    "            water_loss = criterion(outputs, labels.type(torch.LongTensor)) \n",
    "            water_loss.backward()\n",
    "            water_optimizer.step()\n",
    "\n",
    "\n",
    "    print(f\"E: {epoch}; Land Loss: {land_loss.item()}; Water Loss: {water_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifiers for environments only, freezing featurizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in land_net.children():\n",
    "    if layer.__class__.__name__ == 'Linear':\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "for param in water_net.parameters():\n",
    "    if layer.__class__.__name__ == 'Linear':\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "l_optim_frozen = optim.SGD(filter(lambda p: p.requires_grad, land_net.parameters()), lr=lr)\n",
    "w_optim_frozen = optim.SGD(filter(lambda p: p.requires_grad, water_net.parameters()), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
